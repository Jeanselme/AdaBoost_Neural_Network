# AdaBoost_Neural_Network
Test the adaBoost algorithm on multiple neural networks.

## Theory
In order to improve the backpropagation, it is more accurate to associate a stronger weight to inputs which add the most information. In other words, an input which has a wrong computed output.
In order to do so, we developp an algorithm inspired by AdaBoost.

## Execution
```
python3.5 MNIST_Analysis.py
```

## Results

## Libraries
Needs struct, urllib.request, io, gzip, numpy and os. Executed with python3.5
